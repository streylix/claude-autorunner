#!/bin/bash

# Setup script for voice transcription backend
echo "ğŸ¤ Setting up Voice Transcription Backend..."

# Check if backend directory exists
if [ ! -d "backend" ]; then
    echo "âŒ Backend directory not found!"
    exit 1
fi

cd backend

# Check if virtual environment exists
if [ ! -d "venv" ]; then
    echo "ğŸ“¦ Creating Python virtual environment..."
    python3 -m venv venv
fi

# Activate virtual environment
echo "ğŸ”§ Activating virtual environment..."
source venv/bin/activate

# Install/upgrade dependencies
echo "ğŸ“¥ Installing Python dependencies..."
pip install --upgrade pip
pip install -r requirements.txt

# Create database migrations for voice transcription
echo "ğŸ—ƒï¸ Creating database migrations..."
python manage.py makemigrations voice_transcription

# Run migrations
echo "ğŸš€ Running database migrations..."
python manage.py migrate

# Download Whisper base model (this will cache it locally)
echo "ğŸ“¥ Downloading Whisper base model (this may take a few minutes)..."
python -c "
import whisper
import torch

print('Device:', 'cuda' if torch.cuda.is_available() else 'cpu')
print('Loading Whisper base model...')
model = whisper.load_model('base')
print('âœ… Whisper base model downloaded and cached successfully!')
"

echo ""
echo "âœ… Voice transcription backend setup complete!"
echo ""
echo "ğŸ“‹ Next steps:"
echo "   1. Run: ./start_with_backend.sh"
echo "   2. Test voice transcription with Cmd+Shift+V"
echo ""
echo "ğŸ“Š Backend features:"
echo "   â€¢ Offline voice transcription with OpenAI Whisper"
echo "   â€¢ No internet connection required"
echo "   â€¢ Multiple model sizes (tiny, base, small, medium)"
echo "   â€¢ Automatic audio format handling"
echo ""